{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOj4EmvWcodmvgTu35/vJ7E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raghavmahajan821/NLP/blob/main/Tfidf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is TF-IDF?**\n",
        "\n",
        "TF stands for Term Frequency and denotes the ratio of number of times a particular word appeared in a Document to total number of words in the document.\n",
        "\n",
        "\n",
        "     Term Frequency(TF) = [number of times word appeared / total no of words in a document]\n",
        "\n",
        "Term Frequency values ranges between 0 and 1. If a word occurs more number of times, then it's value will be close to 1.\n",
        "\n",
        "IDF stands for Inverse Document Frequency and denotes the log of ratio of total number of documents/datapoints in the whole dataset to the number of documents that contains the particular word.\n",
        "\n",
        "\n",
        "    Inverse Document Frequency(IDF) = [log(Total number of documents / number of documents that contains the word)]\n",
        "\n",
        "\n",
        "In IDF, if a word occured in more number of documents and is common across all documents, then it's value will be less and ratio will approaches to 0.\n",
        "\n",
        "Finally:\n",
        "\n",
        "\n",
        "    TF-IDF = Term Frequency(TF) * Inverse Document Frequency(IDF)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VQ1hEZ471_ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "metadata": {
        "id": "bYIJK32Z1_ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus= [\n",
        "    \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
        "    \"Apple is announcing new iphone tomorrow\",\n",
        "    \"Tesla is announcing new model-3 tomorrow\",\n",
        "    \"Google is announcing new pixel-6 tomorrow\",\n",
        "    \"Microsoft is announcing new surface tomorrow\",\n",
        "    \"Amazon is announcing new eco-dot tomorrow\",\n",
        "    \"I am eating biryani and you are eating grapes\"\n",
        "]"
      ],
      "metadata": {
        "id": "KZcfqr5g2TP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec=TfidfVectorizer()\n",
        "transformed_output=vec.fit_transform(corpus)\n",
        "transformed_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OtWmzsr24j3",
        "outputId": "28d9738e-6bc7-4b30-8806-fdc07c24719a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7x28 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 46 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IcOED2_3uT6",
        "outputId": "33972936-608b-46a8-966d-83b862bb4345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thor eating pizza, Loki is eating pizza, Ironman ate pizza already',\n",
              " 'Apple is announcing new iphone tomorrow']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(transformed_output.toarray()[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsZd9v8r3EgA",
        "outputId": "d6672bae-269a-49f5-dfe8-5889e5ab7ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.24266547 0.         0.         0.         0.         0.\n",
            "  0.         0.24266547 0.         0.         0.40286636 0.\n",
            "  0.         0.         0.         0.24266547 0.11527033 0.24266547\n",
            "  0.         0.         0.         0.         0.72799642 0.\n",
            "  0.         0.24266547 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.30652086 0.5680354\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.5680354  0.         0.26982671 0.\n",
            "  0.         0.         0.30652086 0.         0.         0.\n",
            "  0.         0.         0.30652086 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83LYMfbV3J9w",
        "outputId": "47a11375-c1fc-4cc3-fa64-5f3f6dcb22ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_char_ngrams',\n",
              " '_char_wb_ngrams',\n",
              " '_check_feature_names',\n",
              " '_check_n_features',\n",
              " '_check_params',\n",
              " '_check_stop_words_consistency',\n",
              " '_check_vocabulary',\n",
              " '_count_vocab',\n",
              " '_get_param_names',\n",
              " '_get_tags',\n",
              " '_limit_features',\n",
              " '_more_tags',\n",
              " '_parameter_constraints',\n",
              " '_repr_html_',\n",
              " '_repr_html_inner',\n",
              " '_repr_mimebundle_',\n",
              " '_sort_features',\n",
              " '_stop_words_id',\n",
              " '_tfidf',\n",
              " '_validate_data',\n",
              " '_validate_ngram_range',\n",
              " '_validate_params',\n",
              " '_validate_vocabulary',\n",
              " '_warn_for_unused_params',\n",
              " '_white_spaces',\n",
              " '_word_ngrams',\n",
              " 'analyzer',\n",
              " 'binary',\n",
              " 'build_analyzer',\n",
              " 'build_preprocessor',\n",
              " 'build_tokenizer',\n",
              " 'decode',\n",
              " 'decode_error',\n",
              " 'dtype',\n",
              " 'encoding',\n",
              " 'fit',\n",
              " 'fit_transform',\n",
              " 'fixed_vocabulary_',\n",
              " 'get_feature_names_out',\n",
              " 'get_params',\n",
              " 'get_stop_words',\n",
              " 'idf_',\n",
              " 'input',\n",
              " 'inverse_transform',\n",
              " 'lowercase',\n",
              " 'max_df',\n",
              " 'max_features',\n",
              " 'min_df',\n",
              " 'ngram_range',\n",
              " 'norm',\n",
              " 'preprocessor',\n",
              " 'set_params',\n",
              " 'smooth_idf',\n",
              " 'stop_words',\n",
              " 'stop_words_',\n",
              " 'strip_accents',\n",
              " 'sublinear_tf',\n",
              " 'token_pattern',\n",
              " 'tokenizer',\n",
              " 'transform',\n",
              " 'use_idf',\n",
              " 'vocabulary',\n",
              " 'vocabulary_']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpDAAo1O4ETZ",
        "outputId": "18c824f2-a90b-4ad2-b340-ce35bcce17a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'thor': 25,\n",
              " 'eating': 10,\n",
              " 'pizza': 22,\n",
              " 'loki': 17,\n",
              " 'is': 16,\n",
              " 'ironman': 15,\n",
              " 'ate': 7,\n",
              " 'already': 0,\n",
              " 'apple': 5,\n",
              " 'announcing': 4,\n",
              " 'new': 20,\n",
              " 'iphone': 14,\n",
              " 'tomorrow': 26,\n",
              " 'tesla': 24,\n",
              " 'model': 19,\n",
              " 'google': 12,\n",
              " 'pixel': 21,\n",
              " 'microsoft': 18,\n",
              " 'surface': 23,\n",
              " 'amazon': 2,\n",
              " 'eco': 11,\n",
              " 'dot': 9,\n",
              " 'am': 1,\n",
              " 'biryani': 8,\n",
              " 'and': 3,\n",
              " 'you': 27,\n",
              " 'are': 6,\n",
              " 'grapes': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_features_names=vec.get_feature_names_out()\n",
        "print(all_features_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx0KBXKB4HQe",
        "outputId": "df490449-bd08-4d80-ea0e-771f380ba29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['already' 'am' 'amazon' 'and' 'announcing' 'apple' 'are' 'ate' 'biryani'\n",
            " 'dot' 'eating' 'eco' 'google' 'grapes' 'iphone' 'ironman' 'is' 'loki'\n",
            " 'microsoft' 'model' 'new' 'pixel' 'pizza' 'surface' 'tesla' 'thor'\n",
            " 'tomorrow' 'you']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in all_features_names:\n",
        "  indx=vec.vocabulary_.get(word)\n",
        "  print(f\"{word} {vec.idf_[indx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2apBfcj14bz4",
        "outputId": "ad412cd7-055c-4b11-f438-f557e250a2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "already 2.386294361119891\n",
            "am 2.386294361119891\n",
            "amazon 2.386294361119891\n",
            "and 2.386294361119891\n",
            "announcing 1.2876820724517808\n",
            "apple 2.386294361119891\n",
            "are 2.386294361119891\n",
            "ate 2.386294361119891\n",
            "biryani 2.386294361119891\n",
            "dot 2.386294361119891\n",
            "eating 1.9808292530117262\n",
            "eco 2.386294361119891\n",
            "google 2.386294361119891\n",
            "grapes 2.386294361119891\n",
            "iphone 2.386294361119891\n",
            "ironman 2.386294361119891\n",
            "is 1.1335313926245225\n",
            "loki 2.386294361119891\n",
            "microsoft 2.386294361119891\n",
            "model 2.386294361119891\n",
            "new 1.2876820724517808\n",
            "pixel 2.386294361119891\n",
            "pizza 2.386294361119891\n",
            "surface 2.386294361119891\n",
            "tesla 2.386294361119891\n",
            "thor 2.386294361119891\n",
            "tomorrow 1.2876820724517808\n",
            "you 2.386294361119891\n"
          ]
        }
      ]
    }
  ]
}